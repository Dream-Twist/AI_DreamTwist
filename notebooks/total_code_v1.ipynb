{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "099dbbf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "from datasets import Dataset, DatasetDict\n",
    "from torch.utils.data import Dataset as TorchDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e5ffd2-4a05-4248-be61-b634b445249c",
   "metadata": {},
   "source": [
    "### 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "645ae09b-395d-42fd-a3a5-49440c290cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1930"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_texts = []\n",
    "with open(\"/home/elicer/WKH/data/train_data.txt\", \"r\") as file:\n",
    "    for i in file:\n",
    "        train_texts.append(i.strip())\n",
    "\n",
    "len(train_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e4355b-d829-4a82-9469-cfae61842d2c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### 슬라이딩 윈도우 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ffab9520-b325-4492-9b60-222c04633f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9667a341-3eca-4044-9963-003076ae43fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/elicer/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "72c491b7-8f3b-4e1a-9e22-3510c19fbcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 슬라이딩 윈도우 파라미터\n",
    "window_size = 10  # 윈도우 크기 (문장 수)\n",
    "sliding_step = 5  # 슬라이딩 간격 (문장 수)\n",
    "\n",
    "def sliding_window(sentences, window_size, step):\n",
    "    \"\"\" 문장 리스트에 슬라이딩 윈도우를 적용하는 함수 \"\"\"\n",
    "    windows = []\n",
    "    for start in range(0, len(sentences) - window_size + 1, step):\n",
    "        window = sentences[start:start + window_size]\n",
    "        windows.append(window)\n",
    "    \n",
    "    # 마지막 윈도우 추가 (중복 방지)\n",
    "    if len(sentences) % step != 0:\n",
    "        last_window = sentences[-window_size:]\n",
    "        if last_window not in windows:\n",
    "            windows.append(last_window)\n",
    "    return windows\n",
    "\n",
    "\n",
    "# 동화 데이터에 슬라이딩 윈도우 적용\n",
    "all_story_windows = []\n",
    "\n",
    "for story in train_texts:\n",
    "    # 동화에서 문장 분리\n",
    "    sentences = sent_tokenize(story)\n",
    "\n",
    "    # 슬라이딩 윈도우 적용\n",
    "    story_windows = sliding_window(sentences, window_size, sliding_step)\n",
    "    \n",
    "    all_story_windows.append(story_windows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1110a181-bb63-41b4-9588-8e47ec928ae4",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 예를 들어 문장 수가 충분하지 않은 경우를 확인\n",
    "for i, story in enumerate(train_texts):\n",
    "    sentences = sent_tokenize(story)\n",
    "    if len(sentences) < window_size:\n",
    "        print(f\"Story {i} has less than {window_size} sentences and cannot have any windows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a1ddb358-7127-49fb-a310-0315f82e1e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과를 저장할 리스트\n",
    "all_new_story = []\n",
    "\n",
    "# 전체 all_story_windows에 대해 반복\n",
    "for story_window in all_story_windows:\n",
    "    # 문장들을 저장할 리스트\n",
    "    sentences_list = []\n",
    "    \n",
    "    for sentences in story_window:\n",
    "        # 각 문장을 sentences_list에 추가\n",
    "        sentences_list.extend(sentences)\n",
    "    \n",
    "    # 문장들을 하나의 문자열로 결합 (문장 사이에만 공백을 추가)\n",
    "    new_story = ' '.join(sentences_list)\n",
    "\n",
    "    # 줄바꿈 문자 제거 및 앞뒤 공백 제거\n",
    "    new_story = new_story.replace('\\n', ' ').strip()\n",
    "    \n",
    "    # 결과 리스트에 추가\n",
    "    all_new_story.append(new_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e376af-cdb5-4358-967f-022e3f9341b1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(all_new_story))\n",
    "all_new_story[397]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "23d926c3-d8e4-4cd6-87ad-256dd48e848f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts = all_new_story"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164c5655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from transformers import Trainer, TrainingArguments, GPT2LMHeadModel, PreTrainedTokenizerFast, DataCollatorForLanguageModeling\n",
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "import wandb\n",
    "\n",
    "wandb.login()\n",
    "\n",
    "# GPU 환경에서 사용 가능하도록 변경\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# SKT에서 개발한 한국어 GPT-2 모델, (한국어 텍스트의 생성, 분류, 번역) 등 다양한 자연어 처리 작업에 사용할 수 있는 사전 훈련된 모델\n",
    "model_name = 'skt/kogpt2-base-v2'\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name).to(device)\n",
    "\n",
    "\n",
    "# 토크나이저 로드  (토크나이저는 텍스트를 입력으로 받아서 모델이 처리할 수 있는 형식으로 변환하고, 반대로 모델의 출력을 해석할 수 있는 역할)\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a996a562",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 해당 토큰들은 추가적인 토큰으로, 추가하거나 빼거나 하시면 됩니다!\n",
    "tokenizer.add_special_tokens({'pad_token': '[PAD]'})   # 패딩 토큰 (일정한 길이로 맞추기 위해 사용)\n",
    "tokenizer.add_special_tokens({'bos_token': '<BOS>'})   # 시작 토큰 (더욱더 동화스럽게 만들기 위해 시작 구문 추가) - ex) 옛날 옛날에~\n",
    "tokenizer.add_special_tokens({'eos_token': '<EOS>'})   # 종료 토큰 (더욱더 동화스럽게 만들기 위해 끝 맺음 추가) - ex) 행복하게 살았답니다~\n",
    "tokenizer.add_special_tokens({'sep_token': '<SEP>'})   # 문장 경계 토큰 (새로운 장면이나 시간이 흐른 것을 알리는 문구)\n",
    "\n",
    "# 모델의 임베딩 테이블 크기를 토크나이저 설정에 맞게 재조정\n",
    "model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "# 꿈틀 데이터셋 클래스 정의\n",
    "class DreamTwistDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, texts, tokenizer, max_length):\n",
    "        self.encodings = tokenizer(texts, padding=True, truncation=True, max_length=max_length)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return {key: torch.tensor(val[idx]).to(device) for key, val in self.encodings.items()}\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings.input_ids)\n",
    "\n",
    "# 데이터셋 인스턴스 생성\n",
    "max_length = 512  # 문장 최대 길이로 설정해주시면 됩니다.\n",
    "\n",
    "# 꿈틀 트레인 데이터셋 설정\n",
    "train_dataset = DreamTwistDataset(train_texts, tokenizer, max_length)\n",
    "\n",
    "# 데이터 콜레이터 설정\n",
    "data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer,\n",
    "    mlm=False,\n",
    "    pad_to_multiple_of=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20954a79",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mwkh1204\u001b[0m (\u001b[33mwkh1204-elice\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/elicer/WKH/wandb/run-20240727_125253-ukkringg</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/wkh1204-elice/huggingface/runs/ukkringg' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/wkh1204-elice/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/wkh1204-elice/huggingface' target=\"_blank\">https://wandb.ai/wkh1204-elice/huggingface</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/wkh1204-elice/huggingface/runs/ukkringg' target=\"_blank\">https://wandb.ai/wkh1204-elice/huggingface/runs/ukkringg</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='41381' max='96500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [41381/96500 4:23:05 < 5:50:27, 2.62 it/s, Epoch 21.44/50]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.963000</td>\n",
       "      <td>1.608692</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.787800</td>\n",
       "      <td>1.338791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.507600</td>\n",
       "      <td>1.095997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.320600</td>\n",
       "      <td>0.862129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.071700</td>\n",
       "      <td>0.658608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.920100</td>\n",
       "      <td>0.485693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.720600</td>\n",
       "      <td>0.349013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.569800</td>\n",
       "      <td>0.234010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.480800</td>\n",
       "      <td>0.157418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.343400</td>\n",
       "      <td>0.105507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.284300</td>\n",
       "      <td>0.074770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.229300</td>\n",
       "      <td>0.056483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.178000</td>\n",
       "      <td>0.046837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.152700</td>\n",
       "      <td>0.037962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.118400</td>\n",
       "      <td>0.032460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.114200</td>\n",
       "      <td>0.028131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.089800</td>\n",
       "      <td>0.024582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.023078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.069200</td>\n",
       "      <td>0.020691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>0.067500</td>\n",
       "      <td>0.019269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>0.063200</td>\n",
       "      <td>0.016886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 트레이닝 인자 설정 (여러분들이 인공지능 수업에서 배운 노하우를 활용하여 에포크, 배치사이즈, 스탭 등 자유롭게 조절하여 학습 인자 셋팅)\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=50 ,\n",
    "    per_device_train_batch_size=1,  # 배치 사이즈 조정\n",
    "    save_steps=10_000,\n",
    "    save_total_limit=2,\n",
    "    eval_strategy='epoch',\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=100,\n",
    "    logging_first_step=True,\n",
    "    learning_rate=5e-5,\n",
    "    overwrite_output_dir=True,\n",
    ")\n",
    "\n",
    "# 트레이너 객체 생성 및 훈련\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=train_dataset,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd63919",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = './trained_model/240727_KH_data1930total_newWindows10-5_epoch50_batchSize1'\n",
    "# 모델 저장\n",
    "model.save_pretrained(output_dir)\n",
    "# 토크나이저 저장\n",
    "tokenizer.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "id": "aedbe8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 동화 생성 함수\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "def make_fairy_tale_story(prompt, model, tokenizer, max_length=512, min_length=100, num_beams=5, temperature=0.7, top_k=50, top_p=0.95):\n",
    "    input_ids = tokenizer.encode(prompt, return_tensors='pt').to(device)\n",
    "    attention_mask = torch.ones_like(input_ids).to(device)\n",
    "    num_return_sequences = 1\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model.generate(\n",
    "            input_ids=input_ids.to(model.device),\n",
    "            attention_mask=attention_mask.to(model.device),\n",
    "            max_length=max_length,\n",
    "            min_length=min_length,\n",
    "            num_return_sequences=num_return_sequences,\n",
    "            no_repeat_ngram_size=4,\n",
    "            num_beams = num_beams,\n",
    "            do_sample=True,\n",
    "            temperature=temperature,\n",
    "            top_k=top_k,\n",
    "            top_p=top_p\n",
    "        )\n",
    "\n",
    "    generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "    return generated_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b144f7-2642-443e-85d5-7cda0011e792",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 동화 생성\n",
    "prompt = '아주 먼 옛날 왕자가 살고 있었어요.'\n",
    "fairy_tale_story = make_fairy_tale_story(prompt, model, tokenizer, max_length=512)\n",
    "print(fairy_tale_story)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "id": "a9dccbff",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 메모리 사용량:\n",
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |   1472 MiB |   4313 MiB | 131346 GiB | 131344 GiB |\n",
      "|       from large pool |   1459 MiB |   4300 MiB | 129666 GiB | 129664 GiB |\n",
      "|       from small pool |     13 MiB |     87 MiB |   1679 GiB |   1679 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |   1472 MiB |   4313 MiB | 131346 GiB | 131344 GiB |\n",
      "|       from large pool |   1459 MiB |   4300 MiB | 129666 GiB | 129664 GiB |\n",
      "|       from small pool |     13 MiB |     87 MiB |   1679 GiB |   1679 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Requested memory      |   1460 MiB |   4301 MiB | 129061 GiB | 129060 GiB |\n",
      "|       from large pool |   1447 MiB |   4288 MiB | 127383 GiB | 127381 GiB |\n",
      "|       from small pool |     13 MiB |     87 MiB |   1678 GiB |   1678 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |   1822 MiB |   5978 MiB |   6628 MiB |   4806 MiB |\n",
      "|       from large pool |   1806 MiB |   5884 MiB |   6524 MiB |   4718 MiB |\n",
      "|       from small pool |     16 MiB |     94 MiB |    104 MiB |     88 MiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory | 357832 KiB |   1267 MiB |  92528 GiB |  92528 GiB |\n",
      "|       from large pool | 355164 KiB |   1264 MiB |  90751 GiB |  90750 GiB |\n",
      "|       from small pool |   2668 KiB |     25 MiB |   1777 GiB |   1777 GiB |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |     470    |     821    |   27003 K  |   27002 K  |\n",
      "|       from large pool |     152    |     326    |   14449 K  |   14449 K  |\n",
      "|       from small pool |     318    |     619    |   12553 K  |   12553 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |     470    |     821    |   27003 K  |   27002 K  |\n",
      "|       from large pool |     152    |     326    |   14449 K  |   14449 K  |\n",
      "|       from small pool |     318    |     619    |   12553 K  |   12553 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |      72    |     171    |     195    |     123    |\n",
      "|       from large pool |      64    |     124    |     143    |      79    |\n",
      "|       from small pool |       8    |      47    |      52    |      44    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |      75    |     133    |   14057 K  |   14057 K  |\n",
      "|       from large pool |      69    |     103    |   10318 K  |   10318 K  |\n",
      "|       from small pool |       6    |      52    |    3739 K  |    3739 K  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 모델 학습 후 GPU 메모리 초기화\n",
    "def clear_gpu_memory():\n",
    "    # GPU 메모리의 캐시 비우기\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    # GPU 메모리 사용량 확인 (선택 사항)\n",
    "    print(\"GPU 메모리 사용량:\")\n",
    "    print(torch.cuda.memory_summary())\n",
    "\n",
    "# 모델 학습 완료 후 GPU 메모리 초기화\n",
    "clear_gpu_memory()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
